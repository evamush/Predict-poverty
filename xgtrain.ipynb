{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import RandomState\n",
    "from numpy import unravel_index\n",
    "\n",
    "\n",
    "import time\n",
    "# data directory\n",
    "DATA_DIR = os.path.join('Kaggle', 'poverty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_paths = {'A': {'train': os.path.join(DATA_DIR, 'A_hhold_train.csv'), \n",
    "                    'test':  os.path.join(DATA_DIR, 'A_hhold_test.csv')}, \n",
    "              \n",
    "              'B': {'train': os.path.join(DATA_DIR, 'B_hhold_train.csv'), \n",
    "                    'test':  os.path.join(DATA_DIR, 'B_hhold_test.csv')}, \n",
    "              \n",
    "              'C': {'train': os.path.join(DATA_DIR, 'C_hhold_train.csv'), \n",
    "                    'test':  os.path.join(DATA_DIR, 'C_hhold_test.csv')}}\n",
    "ind_paths = {'A': {'train': os.path.join(DATA_DIR, 'A_indiv_train.csv'), \n",
    "                    'test':  os.path.join(DATA_DIR, 'A_indiv_test.csv')}, \n",
    "              \n",
    "              'B': {'train': os.path.join(DATA_DIR, 'B_indiv_train.csv'), \n",
    "                    'test':  os.path.join(DATA_DIR, 'B_indiv_test.csv')}, \n",
    "              \n",
    "              'C': {'train': os.path.join(DATA_DIR, 'C_indiv_train.csv'), \n",
    "                    'test':  os.path.join(DATA_DIR, 'C_indiv_test.csv')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_train = pd.read_csv('A_hhold_train.csv', index_col='id')\n",
    "b_train = pd.read_csv('B_hhold_train.csv', index_col='id')\n",
    "c_train = pd.read_csv('C_hhold_train.csv', index_col='id')\n",
    "ai_train = pd.read_csv('A_indiv_train.csv', index_col='id')\n",
    "bi_train = pd.read_csv('B_indiv_train.csv', index_col='id').drop('wJthinfa',axis=1)\n",
    "ci_train = pd.read_csv('c_indiv_train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_test = pd.read_csv('A_hhold_test.csv', index_col='id')\n",
    "b_test = pd.read_csv('B_hhold_test.csv', index_col='id')\n",
    "c_test = pd.read_csv('C_hhold_test.csv', index_col='id')\n",
    "ai_test = pd.read_csv('A_indiv_test.csv', index_col='id')\n",
    "bi_test = pd.read_csv('B_indiv_test.csv', index_col='id').drop('wJthinfa',axis=1)\n",
    "ci_test = pd.read_csv('C_indiv_test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "def standardize(df, numeric_only=True):\n",
    "    numeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "    df[numeric.columns] = (numeric - numeric.mean()) / numeric.std()\n",
    "    return df\n",
    "    \n",
    "\n",
    "def pre_process_data(df, enforce_cols=None):\n",
    "#     df = standardize(df)\n",
    "    df = pd.get_dummies(df)\n",
    "    print(\"After converting categoricals:\\t{}\".format(df.shape))\n",
    "    if enforce_cols is not None:\n",
    "        to_drop = np.setdiff1d(df.columns, enforce_cols)\n",
    "        to_add = np.setdiff1d(enforce_cols, df.columns)\n",
    "\n",
    "        df.drop(to_drop, axis=1, inplace=True)\n",
    "        df = df.assign(**{c: 0 for c in to_add})\n",
    "    \n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df \n",
    "def drop(df, col, threshold):\n",
    "    poor_count = sum(df['poor'])\n",
    "    non_count = df.shape[0]-poor_count\n",
    "    col_poor = Counter(df[col][df['poor'] == True])\n",
    "    col_non_poor = Counter(df[col][df['poor'] == False])\n",
    "    key = set(col_poor.keys())|set(col_poor.keys())\n",
    "    poor_value, non_poor_value = any([i/poor_count>threshold for i in col_poor.values()]), any([i/non_count>threshold for i in col_non_poor.values()])\n",
    "    if poor_value & non_poor_value:\n",
    "        return df.drop([col],axis=1)\n",
    "    else: return df\n",
    "\n",
    "def drop_col(hhold, indi, hhold_threshold, indi_threshold):\n",
    "    hhold_poor = sum(hhold['poor'])\n",
    "    hhold_no = hhold.shape[0] - hhold_poor\n",
    "    indi_poor = sum(indi['poor'])\n",
    "    indi_no = indi.shape[0] - indi_poor\n",
    "    for col in hhold:\n",
    "        if col == 'poor' or col == 'country': continue\n",
    "        h_col_poor = Counter(hhold[col][hhold['poor'] == True])\n",
    "        h_col_non = Counter(hhold[col][hhold['poor'] == False])\n",
    "        if any([i/hhold_poor>hhold_threshold for i in h_col_poor.values()]) & any([i/hhold_no>hhold_threshold for i in h_col_non.values()]):\n",
    "            hhold = hhold.drop([col], axis = 1)\n",
    "    for col in indi:\n",
    "        if col == 'poor' or col == 'country' or col == 'iid': continue\n",
    "        i_col_poor = Counter(indi[col][indi['poor'] == True])\n",
    "        i_col_non = Counter(indi[col][indi['poor'] == False])\n",
    "        if any([i/indi_poor>indi_threshold for i in i_col_poor.values()]) & any([i/indi_no>indi_threshold for i in i_col_non.values()]):\n",
    "            indi = indi.drop([col], axis = 1)\n",
    "    return hhold, indi.drop(['poor','country'],axis=1)\n",
    "    \n",
    "def combine_hhold_indi(hhold, indi):\n",
    "    hhold = pre_process_data(hhold)\n",
    "    iid_count = pd.DataFrame(indi.groupby('id')['iid'].count())\n",
    "    iid_count.columns = ['family_numbers']\n",
    "    indi = indi.drop('iid',axis=1)\n",
    "    indi_num = indi.select_dtypes(include=['int64', 'float64'])\n",
    "    indi_obj = indi.drop(list(indi_num.columns), axis = 1)\n",
    "    indi_obj = pd.get_dummies(indi_obj)\n",
    "    indi_num = indi_num.fillna(indi_num.mean())\n",
    "    indi_obj = pre_process_data(indi_obj)\n",
    "    indi_num = indi_num.groupby('id')[list(indi_num.columns)].mean()\n",
    "#     indi_num = standardize(indi_num)\n",
    "    indi_obj = indi_obj.groupby('id')[list(indi_obj.columns)].sum()/indi_obj.groupby('id')[list(indi_obj.columns)].count()\n",
    "    com = pd.concat([iid_count,indi_num,indi_obj,hhold],axis=1)\n",
    "    com.fillna(-100,inplace=True)\n",
    "    return com\n",
    "\n",
    "def order(df_test, df_train, ori_test):\n",
    "    new_df = pd.DataFrame()\n",
    "    for key in df_train:\n",
    "        new_df[key] = df_test[key]\n",
    "    new_df = new_df.loc[ori_test.index]\n",
    "    return new_df\n",
    "def mll(y_true,y_pred):\n",
    "    loss = 0\n",
    "    for i in range(3):\n",
    "        for j in range(len(y_true[i])):\n",
    "            loss += y_true[i][j]*np.log(y_pred[i][j])+(1-y_true[i][j])*np.log(1-y_pred[i][j])\n",
    "        loss = loss / (j+1)\n",
    "    return -loss/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_test_hhold_indi(hhold, indi, train):\n",
    "    hhold = pre_process_data(hhold.drop('country',axis = 1))\n",
    "    iid_count = pd.DataFrame(indi.groupby('id')['iid'].count())\n",
    "    iid_count.columns = ['family_numbers']\n",
    "    indi = indi.drop('iid',axis=1)\n",
    "    indi_num = indi.select_dtypes(include=['int64', 'float64'])\n",
    "    indi_obj = indi.drop(list(indi_num.columns), axis = 1)\n",
    "    indi_obj = pd.get_dummies(indi_obj)\n",
    "    indi_num = indi_num.fillna(indi_num.mean())\n",
    "    indi_obj = pre_process_data(indi_obj)\n",
    "    indi_num = indi_num.groupby('id')[list(indi_num.columns)].mean()\n",
    "#     indi_num = standardize(indi_num)\n",
    "    indi_obj = indi_obj.groupby('id')[list(indi_obj.columns)].sum()/indi_obj.groupby('id')[list(indi_obj.columns)].count()\n",
    "    com = pd.concat([iid_count,indi_num,indi_obj,hhold],axis=1)\n",
    "    to_drop = np.setdiff1d(com.columns, train.columns)\n",
    "    to_add = np.setdiff1d(train.columns, com.columns)\n",
    "\n",
    "    com.drop(to_drop, axis=1, inplace=True)\n",
    "    com = com.assign(**{c: 0 for c in to_add})\n",
    "    \n",
    "    com.fillna(0, inplace=True)\n",
    "    return com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After converting categoricals:\t(8203, 612)\n",
      "After converting categoricals:\t(37560, 255)\n",
      "After converting categoricals:\t(3255, 1221)\n",
      "After converting categoricals:\t(20252, 1039)\n",
      "After converting categoricals:\t(6469, 741)\n",
      "After converting categoricals:\t(29913, 279)\n"
     ]
    }
   ],
   "source": [
    "train_a,train_ai = drop_col(a_train,ai_train,0.95,0.95)\n",
    "A_train = combine_hhold_indi(train_a,train_ai)\n",
    "train_b,train_bi = drop_col(b_train,bi_train,0.95,0.95)\n",
    "B_train = combine_hhold_indi(train_b,train_bi)\n",
    "train_c,train_ci = drop_col(c_train,ci_train,0.95,0.95)\n",
    "C_train = combine_hhold_indi(train_c,train_ci)\n",
    "A_train = A_train.sample(frac=1)\n",
    "B_train = B_train.sample(frac=1)\n",
    "C_train = C_train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After converting categoricals:\t(4041, 850)\n",
      "After converting categoricals:\t(18535, 271)\n",
      "After converting categoricals:\t(1604, 1418)\n",
      "After converting categoricals:\t(10066, 1502)\n",
      "After converting categoricals:\t(3187, 772)\n",
      "After converting categoricals:\t(14701, 296)\n"
     ]
    }
   ],
   "source": [
    "ax = A_train.drop('poor', axis = 1) \n",
    "ay = A_train['poor'].values\n",
    "bx = B_train.drop('poor', axis = 1) \n",
    "by = B_train['poor'].values\n",
    "cx = C_train.drop('poor', axis = 1) \n",
    "cy = C_train['poor'].values\n",
    "A_test = combine_test_hhold_indi(a_test, ai_test, ax)\n",
    "B_test = combine_test_hhold_indi(b_test, bi_test, bx)\n",
    "C_test = combine_test_hhold_indi(c_test, ci_test, cx)\n",
    "A_test = order(A_test, ax, a_test)\n",
    "B_test = order(B_test, bx, b_test)\n",
    "C_test = order(C_test, cx, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanwen/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/fanwen/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6562 Validation samples: 1641\n"
     ]
    }
   ],
   "source": [
    "ax_train,ax_valid,ay_train,ay_valid = train_test_split(ax, ay, test_size=0.2, random_state=4242)\n",
    "print('Train samples: {} Validation samples: {}'.format(len(ax_train), len(ax_valid)))\n",
    "bx_train,bx_valid,by_train,by_valid = train_test_split(bx, by, test_size=0.2, random_state=4242)\n",
    "cx_train,cx_valid,cy_train,cy_valid = train_test_split(cx, cy, test_size=0.2, random_state=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_train = xgb.DMatrix(ax_train, ay_train)\n",
    "a_valid = xgb.DMatrix(ax_valid, ay_valid)\n",
    "a_test = xgb.DMatrix(A_test)\n",
    "b_train = xgb.DMatrix(bx_train, by_train)\n",
    "b_valid = xgb.DMatrix(bx_valid, by_valid)\n",
    "b_test = xgb.DMatrix(B_test)\n",
    "c_train = xgb.DMatrix(cx_train, cy_train)\n",
    "c_valid = xgb.DMatrix(cx_valid, cy_valid)\n",
    "c_test = xgb.DMatrix(C_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.02\n",
    "params['silent'] = True\n",
    "params['max_depth'] = 6\n",
    "params['subsample'] = 0.9\n",
    "params['colsample_bytree'] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual,pred,cmpcol = 0,sortcol = 1):\n",
    "    assert(len(actual)== len(pred))\n",
    "    all = np.asarray(np.c_[actual,pred,np.arange(len(actual))],dtype = np.float)\n",
    "    all = all[np.lexsort((all[:,2],-1*all[:,1]))]\n",
    "    totallosses = all[:,0].sum()\n",
    "    ginisum = all[:,0].cumsum().sum()/totallosses\n",
    "    \n",
    "    ginisum -= (len(actual)+1)/2\n",
    "    return ginisum/len(actual)\n",
    "def gini_normalized(a,p):\n",
    "    return gini(a,p)/gini(a,a)\n",
    "def gini_xgb(preds,dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels,preds)\n",
    "    return [(\"gini\",gini_score)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.167784\tvalid-error:0.210238\ttrain-gini:0.788735\tvalid-gini:0.727963\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[10]\ttrain-error:0.146754\tvalid-error:0.188909\ttrain-gini:0.864997\tvalid-gini:0.778838\n",
      "[20]\ttrain-error:0.133496\tvalid-error:0.182815\ttrain-gini:0.884366\tvalid-gini:0.793323\n",
      "[30]\ttrain-error:0.124505\tvalid-error:0.176722\ttrain-gini:0.895611\tvalid-gini:0.803274\n",
      "[40]\ttrain-error:0.119781\tvalid-error:0.171846\ttrain-gini:0.905231\tvalid-gini:0.812581\n",
      "[50]\ttrain-error:0.114599\tvalid-error:0.166971\ttrain-gini:0.913201\tvalid-gini:0.821324\n",
      "[60]\ttrain-error:0.109418\tvalid-error:0.166362\ttrain-gini:0.919341\tvalid-gini:0.827803\n",
      "[70]\ttrain-error:0.106675\tvalid-error:0.162706\ttrain-gini:0.925568\tvalid-gini:0.834047\n",
      "[80]\ttrain-error:0.100427\tvalid-error:0.162096\ttrain-gini:0.932171\tvalid-gini:0.839426\n",
      "[90]\ttrain-error:0.097074\tvalid-error:0.157831\ttrain-gini:0.936735\tvalid-gini:0.843787\n",
      "[100]\ttrain-error:0.092655\tvalid-error:0.159659\ttrain-gini:0.942047\tvalid-gini:0.848346\n",
      "[110]\ttrain-error:0.087778\tvalid-error:0.159049\ttrain-gini:0.946642\tvalid-gini:0.852923\n",
      "[120]\ttrain-error:0.084578\tvalid-error:0.159049\ttrain-gini:0.950308\tvalid-gini:0.856299\n",
      "[130]\ttrain-error:0.080768\tvalid-error:0.152956\ttrain-gini:0.953863\tvalid-gini:0.859657\n",
      "[140]\ttrain-error:0.079549\tvalid-error:0.149909\ttrain-gini:0.956649\tvalid-gini:0.862672\n",
      "[150]\ttrain-error:0.076044\tvalid-error:0.14808\ttrain-gini:0.959353\tvalid-gini:0.865928\n",
      "[160]\ttrain-error:0.073301\tvalid-error:0.143815\ttrain-gini:0.962002\tvalid-gini:0.868394\n",
      "[170]\ttrain-error:0.070558\tvalid-error:0.141377\ttrain-gini:0.964196\tvalid-gini:0.870502\n",
      "[180]\ttrain-error:0.068272\tvalid-error:0.142596\ttrain-gini:0.966345\tvalid-gini:0.872487\n",
      "[190]\ttrain-error:0.0669\tvalid-error:0.13833\ttrain-gini:0.968567\tvalid-gini:0.873896\n",
      "[200]\ttrain-error:0.06431\tvalid-error:0.13833\ttrain-gini:0.970143\tvalid-gini:0.875082\n",
      "[210]\ttrain-error:0.061719\tvalid-error:0.139549\ttrain-gini:0.971932\tvalid-gini:0.876479\n",
      "[220]\ttrain-error:0.059433\tvalid-error:0.139549\ttrain-gini:0.973698\tvalid-gini:0.878281\n",
      "[230]\ttrain-error:0.057757\tvalid-error:0.137721\ttrain-gini:0.97521\tvalid-gini:0.878981\n",
      "[240]\ttrain-error:0.054557\tvalid-error:0.136502\ttrain-gini:0.976618\tvalid-gini:0.880239\n",
      "[250]\ttrain-error:0.052575\tvalid-error:0.137721\ttrain-gini:0.97807\tvalid-gini:0.881371\n",
      "[260]\ttrain-error:0.04968\tvalid-error:0.137112\ttrain-gini:0.979361\tvalid-gini:0.882699\n",
      "[270]\ttrain-error:0.047699\tvalid-error:0.134674\ttrain-gini:0.980689\tvalid-gini:0.883543\n",
      "[280]\ttrain-error:0.04648\tvalid-error:0.134065\ttrain-gini:0.98195\tvalid-gini:0.884627\n",
      "[290]\ttrain-error:0.044651\tvalid-error:0.134065\ttrain-gini:0.982971\tvalid-gini:0.885393\n",
      "[300]\ttrain-error:0.042518\tvalid-error:0.132236\ttrain-gini:0.984022\tvalid-gini:0.886432\n",
      "[310]\ttrain-error:0.040841\tvalid-error:0.134674\ttrain-gini:0.98496\tvalid-gini:0.887297\n",
      "[320]\ttrain-error:0.040079\tvalid-error:0.132846\ttrain-gini:0.98578\tvalid-gini:0.888192\n",
      "[330]\ttrain-error:0.038403\tvalid-error:0.129799\ttrain-gini:0.986733\tvalid-gini:0.889021\n",
      "[340]\ttrain-error:0.037489\tvalid-error:0.131018\ttrain-gini:0.987344\tvalid-gini:0.889354\n",
      "[350]\ttrain-error:0.036269\tvalid-error:0.131627\ttrain-gini:0.988241\tvalid-gini:0.889724\n",
      "[360]\ttrain-error:0.035507\tvalid-error:0.132236\ttrain-gini:0.988983\tvalid-gini:0.890099\n",
      "[370]\ttrain-error:0.034288\tvalid-error:0.131018\ttrain-gini:0.989733\tvalid-gini:0.890496\n",
      "[380]\ttrain-error:0.03246\tvalid-error:0.131018\ttrain-gini:0.990432\tvalid-gini:0.890916\n",
      "[390]\ttrain-error:0.030936\tvalid-error:0.130408\ttrain-gini:0.99105\tvalid-gini:0.891268\n",
      "[400]\ttrain-error:0.029869\tvalid-error:0.131018\ttrain-gini:0.991688\tvalid-gini:0.89155\n",
      "[410]\ttrain-error:0.028955\tvalid-error:0.129799\ttrain-gini:0.992124\tvalid-gini:0.892265\n",
      "[420]\ttrain-error:0.027735\tvalid-error:0.12919\ttrain-gini:0.992606\tvalid-gini:0.892721\n",
      "[430]\ttrain-error:0.026669\tvalid-error:0.12919\ttrain-gini:0.992982\tvalid-gini:0.893139\n",
      "[440]\ttrain-error:0.025602\tvalid-error:0.12919\ttrain-gini:0.993403\tvalid-gini:0.893541\n",
      "[450]\ttrain-error:0.02423\tvalid-error:0.12919\ttrain-gini:0.993898\tvalid-gini:0.893805\n",
      "[460]\ttrain-error:0.023468\tvalid-error:0.12919\ttrain-gini:0.994351\tvalid-gini:0.894292\n",
      "[470]\ttrain-error:0.022402\tvalid-error:0.127361\ttrain-gini:0.994799\tvalid-gini:0.894376\n",
      "[480]\ttrain-error:0.021945\tvalid-error:0.127361\ttrain-gini:0.995137\tvalid-gini:0.894857\n",
      "[490]\ttrain-error:0.021183\tvalid-error:0.127361\ttrain-gini:0.995481\tvalid-gini:0.895244\n",
      "[500]\ttrain-error:0.020725\tvalid-error:0.127361\ttrain-gini:0.995779\tvalid-gini:0.895115\n",
      "[510]\ttrain-error:0.020116\tvalid-error:0.127361\ttrain-gini:0.995986\tvalid-gini:0.895202\n",
      "[520]\ttrain-error:0.019506\tvalid-error:0.126143\ttrain-gini:0.996295\tvalid-gini:0.895617\n",
      "[530]\ttrain-error:0.018897\tvalid-error:0.126143\ttrain-gini:0.996552\tvalid-gini:0.895875\n",
      "[540]\ttrain-error:0.01783\tvalid-error:0.126143\ttrain-gini:0.996759\tvalid-gini:0.896121\n",
      "[550]\ttrain-error:0.01722\tvalid-error:0.126143\ttrain-gini:0.997029\tvalid-gini:0.896328\n",
      "[560]\ttrain-error:0.016611\tvalid-error:0.126143\ttrain-gini:0.997249\tvalid-gini:0.896848\n",
      "[570]\ttrain-error:0.015239\tvalid-error:0.125533\ttrain-gini:0.997504\tvalid-gini:0.897037\n",
      "[580]\ttrain-error:0.014325\tvalid-error:0.124924\ttrain-gini:0.997688\tvalid-gini:0.897491\n",
      "[590]\ttrain-error:0.013563\tvalid-error:0.125533\ttrain-gini:0.997899\tvalid-gini:0.897497\n",
      "[600]\ttrain-error:0.013563\tvalid-error:0.125533\ttrain-gini:0.998055\tvalid-gini:0.89756\n",
      "[610]\ttrain-error:0.013563\tvalid-error:0.126143\ttrain-gini:0.998194\tvalid-gini:0.89774\n",
      "[620]\ttrain-error:0.012953\tvalid-error:0.127361\ttrain-gini:0.998331\tvalid-gini:0.898139\n",
      "[630]\ttrain-error:0.012953\tvalid-error:0.126143\ttrain-gini:0.998439\tvalid-gini:0.898362\n",
      "[640]\ttrain-error:0.012039\tvalid-error:0.124314\ttrain-gini:0.998547\tvalid-gini:0.898374\n",
      "[650]\ttrain-error:0.011429\tvalid-error:0.124314\ttrain-gini:0.998671\tvalid-gini:0.89841\n",
      "[660]\ttrain-error:0.011125\tvalid-error:0.124314\ttrain-gini:0.998778\tvalid-gini:0.898794\n",
      "[670]\ttrain-error:0.011277\tvalid-error:0.123705\ttrain-gini:0.998894\tvalid-gini:0.898719\n",
      "[680]\ttrain-error:0.01082\tvalid-error:0.124314\ttrain-gini:0.998984\tvalid-gini:0.898821\n",
      "[690]\ttrain-error:0.009906\tvalid-error:0.124314\ttrain-gini:0.999069\tvalid-gini:0.898992\n",
      "[700]\ttrain-error:0.009753\tvalid-error:0.123096\ttrain-gini:0.999138\tvalid-gini:0.898884\n",
      "[710]\ttrain-error:0.009448\tvalid-error:0.123096\ttrain-gini:0.999199\tvalid-gini:0.898887\n",
      "[720]\ttrain-error:0.008686\tvalid-error:0.123705\ttrain-gini:0.999275\tvalid-gini:0.899028\n",
      "[730]\ttrain-error:0.008534\tvalid-error:0.123096\ttrain-gini:0.999348\tvalid-gini:0.899146\n",
      "[740]\ttrain-error:0.008534\tvalid-error:0.123096\ttrain-gini:0.999396\tvalid-gini:0.899338\n",
      "[750]\ttrain-error:0.008382\tvalid-error:0.123096\ttrain-gini:0.999467\tvalid-gini:0.899416\n",
      "[760]\ttrain-error:0.008382\tvalid-error:0.123096\ttrain-gini:0.999516\tvalid-gini:0.899338\n",
      "[770]\ttrain-error:0.007924\tvalid-error:0.122486\ttrain-gini:0.999559\tvalid-gini:0.899437\n",
      "[780]\ttrain-error:0.00762\tvalid-error:0.123705\ttrain-gini:0.99959\tvalid-gini:0.899431\n",
      "[790]\ttrain-error:0.007467\tvalid-error:0.122486\ttrain-gini:0.999639\tvalid-gini:0.899563\n",
      "[800]\ttrain-error:0.007162\tvalid-error:0.122486\ttrain-gini:0.999666\tvalid-gini:0.899638\n",
      "[810]\ttrain-error:0.006858\tvalid-error:0.122486\ttrain-gini:0.999699\tvalid-gini:0.899584\n",
      "[820]\ttrain-error:0.006096\tvalid-error:0.123096\ttrain-gini:0.999735\tvalid-gini:0.89971\n",
      "[830]\ttrain-error:0.005334\tvalid-error:0.121877\ttrain-gini:0.99976\tvalid-gini:0.899773\n",
      "[840]\ttrain-error:0.005029\tvalid-error:0.123096\ttrain-gini:0.999776\tvalid-gini:0.89989\n",
      "[850]\ttrain-error:0.004419\tvalid-error:0.122486\ttrain-gini:0.999802\tvalid-gini:0.900167\n",
      "[860]\ttrain-error:0.004267\tvalid-error:0.123096\ttrain-gini:0.999822\tvalid-gini:0.900098\n",
      "[870]\ttrain-error:0.004115\tvalid-error:0.123705\ttrain-gini:0.999837\tvalid-gini:0.900404\n",
      "[880]\ttrain-error:0.003962\tvalid-error:0.125533\ttrain-gini:0.999856\tvalid-gini:0.900392\n",
      "[890]\ttrain-error:0.003962\tvalid-error:0.124314\ttrain-gini:0.999871\tvalid-gini:0.900614\n",
      "[900]\ttrain-error:0.003657\tvalid-error:0.124924\ttrain-gini:0.999885\tvalid-gini:0.900506\n",
      "[910]\ttrain-error:0.003657\tvalid-error:0.125533\ttrain-gini:0.999899\tvalid-gini:0.900692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[920]\ttrain-error:0.003505\tvalid-error:0.124924\ttrain-gini:0.999911\tvalid-gini:0.900755\n",
      "[930]\ttrain-error:0.003353\tvalid-error:0.127361\ttrain-gini:0.999921\tvalid-gini:0.900915\n",
      "[940]\ttrain-error:0.0032\tvalid-error:0.125533\ttrain-gini:0.999934\tvalid-gini:0.900909\n",
      "[950]\ttrain-error:0.003048\tvalid-error:0.125533\ttrain-gini:0.999946\tvalid-gini:0.900984\n",
      "[960]\ttrain-error:0.003048\tvalid-error:0.126752\ttrain-gini:0.999952\tvalid-gini:0.901179\n",
      "[970]\ttrain-error:0.003048\tvalid-error:0.126143\ttrain-gini:0.999959\tvalid-gini:0.901236\n",
      "[980]\ttrain-error:0.003048\tvalid-error:0.125533\ttrain-gini:0.999964\tvalid-gini:0.901272\n",
      "[990]\ttrain-error:0.002743\tvalid-error:0.127361\ttrain-gini:0.999971\tvalid-gini:0.901338\n",
      "[1000]\ttrain-error:0.002743\tvalid-error:0.126752\ttrain-gini:0.999976\tvalid-gini:0.901413\n",
      "[1010]\ttrain-error:0.002743\tvalid-error:0.127361\ttrain-gini:0.99998\tvalid-gini:0.901338\n",
      "[1020]\ttrain-error:0.002438\tvalid-error:0.126143\ttrain-gini:0.999983\tvalid-gini:0.901536\n",
      "[1030]\ttrain-error:0.002438\tvalid-error:0.125533\ttrain-gini:0.999985\tvalid-gini:0.901569\n",
      "[1040]\ttrain-error:0.002133\tvalid-error:0.127361\ttrain-gini:0.999987\tvalid-gini:0.901497\n",
      "[1050]\ttrain-error:0.001981\tvalid-error:0.127361\ttrain-gini:0.999989\tvalid-gini:0.901407\n",
      "[1060]\ttrain-error:0.001829\tvalid-error:0.125533\ttrain-gini:0.999991\tvalid-gini:0.90144\n",
      "[1070]\ttrain-error:0.001524\tvalid-error:0.124924\ttrain-gini:0.999993\tvalid-gini:0.901596\n",
      "[1080]\ttrain-error:0.001524\tvalid-error:0.125533\ttrain-gini:0.999995\tvalid-gini:0.901656\n",
      "[1090]\ttrain-error:0.001524\tvalid-error:0.125533\ttrain-gini:0.999995\tvalid-gini:0.901605\n",
      "[1100]\ttrain-error:0.001372\tvalid-error:0.125533\ttrain-gini:0.999996\tvalid-gini:0.901551\n",
      "[1110]\ttrain-error:0.001372\tvalid-error:0.125533\ttrain-gini:0.999997\tvalid-gini:0.901647\n",
      "[1120]\ttrain-error:0.001219\tvalid-error:0.126143\ttrain-gini:0.999998\tvalid-gini:0.901719\n",
      "[1130]\ttrain-error:0.001219\tvalid-error:0.125533\ttrain-gini:0.999998\tvalid-gini:0.901575\n",
      "[1140]\ttrain-error:0.001219\tvalid-error:0.124924\ttrain-gini:0.999998\tvalid-gini:0.901527\n",
      "[1150]\ttrain-error:0.001219\tvalid-error:0.126143\ttrain-gini:0.999999\tvalid-gini:0.901398\n",
      "[1160]\ttrain-error:0.001219\tvalid-error:0.126752\ttrain-gini:0.999999\tvalid-gini:0.901395\n",
      "[1170]\ttrain-error:0.000914\tvalid-error:0.127361\ttrain-gini:0.999999\tvalid-gini:0.901524\n",
      "[1180]\ttrain-error:0.00061\tvalid-error:0.126143\ttrain-gini:0.999999\tvalid-gini:0.901527\n",
      "[1190]\ttrain-error:0.00061\tvalid-error:0.125533\ttrain-gini:0.999999\tvalid-gini:0.901692\n",
      "[1200]\ttrain-error:0.00061\tvalid-error:0.126143\ttrain-gini:0.999999\tvalid-gini:0.901855\n",
      "[1210]\ttrain-error:0.00061\tvalid-error:0.125533\ttrain-gini:0.999999\tvalid-gini:0.901885\n",
      "[1220]\ttrain-error:0.00061\tvalid-error:0.124924\ttrain-gini:1\tvalid-gini:0.901936\n",
      "[1230]\ttrain-error:0.000457\tvalid-error:0.126143\ttrain-gini:1\tvalid-gini:0.901894\n",
      "[1240]\ttrain-error:0.000457\tvalid-error:0.126143\ttrain-gini:1\tvalid-gini:0.901957\n",
      "[1250]\ttrain-error:0.000457\tvalid-error:0.126752\ttrain-gini:1\tvalid-gini:0.90208\n",
      "[1260]\ttrain-error:0.000457\tvalid-error:0.125533\ttrain-gini:1\tvalid-gini:0.90214\n",
      "[1270]\ttrain-error:0.000457\tvalid-error:0.124924\ttrain-gini:1\tvalid-gini:0.902338\n",
      "[1280]\ttrain-error:0.000305\tvalid-error:0.126143\ttrain-gini:1\tvalid-gini:0.90235\n",
      "[1290]\ttrain-error:0.000305\tvalid-error:0.125533\ttrain-gini:1\tvalid-gini:0.902383\n",
      "[1300]\ttrain-error:0.000152\tvalid-error:0.125533\ttrain-gini:1\tvalid-gini:0.902497\n",
      "[1310]\ttrain-error:0.000152\tvalid-error:0.125533\ttrain-gini:1\tvalid-gini:0.902548\n",
      "[1320]\ttrain-error:0.000152\tvalid-error:0.127361\ttrain-gini:1\tvalid-gini:0.902473\n",
      "[1330]\ttrain-error:0.000152\tvalid-error:0.126752\ttrain-gini:1\tvalid-gini:0.902497\n",
      "[1340]\ttrain-error:0.000152\tvalid-error:0.126143\ttrain-gini:1\tvalid-gini:0.902699\n",
      "[1350]\ttrain-error:0.000152\tvalid-error:0.126143\ttrain-gini:1\tvalid-gini:0.902798\n",
      "[1360]\ttrain-error:0.000152\tvalid-error:0.127361\ttrain-gini:1\tvalid-gini:0.902945\n",
      "[1370]\ttrain-error:0.000152\tvalid-error:0.127361\ttrain-gini:1\tvalid-gini:0.902858\n",
      "[1380]\ttrain-error:0\tvalid-error:0.127361\ttrain-gini:1\tvalid-gini:0.902771\n",
      "[1390]\ttrain-error:0\tvalid-error:0.126143\ttrain-gini:1\tvalid-gini:0.902684\n",
      "[1400]\ttrain-error:0\tvalid-error:0.124924\ttrain-gini:1\tvalid-gini:0.902654\n",
      "[1410]\ttrain-error:0\tvalid-error:0.125533\ttrain-gini:1\tvalid-gini:0.902708\n",
      "[1420]\ttrain-error:0\tvalid-error:0.125533\ttrain-gini:1\tvalid-gini:0.902738\n",
      "[1430]\ttrain-error:0\tvalid-error:0.126752\ttrain-gini:1\tvalid-gini:0.902626\n",
      "[1440]\ttrain-error:0\tvalid-error:0.126752\ttrain-gini:1\tvalid-gini:0.902666\n",
      "[1450]\ttrain-error:0\tvalid-error:0.126143\ttrain-gini:1\tvalid-gini:0.902705\n",
      "[1460]\ttrain-error:0\tvalid-error:0.126143\ttrain-gini:1\tvalid-gini:0.902849\n",
      "Stopping. Best iteration:\n",
      "[1360]\ttrain-error:0.000152\tvalid-error:0.127361\ttrain-gini:1\tvalid-gini:0.902945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(a_train, 'train'), (a_valid, 'valid')]\n",
    "model_A = xgb.train(params, a_train, 3000, watchlist,feval=gini_xgb,early_stopping_rounds=100, maximize=True, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.05914\tvalid-error:0.092166\ttrain-gini:0.593721\tvalid-gini:0.278735\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[10]\ttrain-error:0.058756\tvalid-error:0.076805\ttrain-gini:0.836096\tvalid-gini:0.524393\n",
      "[20]\ttrain-error:0.057604\tvalid-error:0.078341\ttrain-gini:0.868216\tvalid-gini:0.581431\n",
      "[30]\ttrain-error:0.0553\tvalid-error:0.076805\ttrain-gini:0.901541\tvalid-gini:0.622696\n",
      "[40]\ttrain-error:0.054147\tvalid-error:0.076805\ttrain-gini:0.928725\tvalid-gini:0.610516\n",
      "[50]\ttrain-error:0.050691\tvalid-error:0.076805\ttrain-gini:0.948356\tvalid-gini:0.619368\n",
      "[60]\ttrain-error:0.049539\tvalid-error:0.078341\ttrain-gini:0.965512\tvalid-gini:0.61371\n",
      "[70]\ttrain-error:0.046467\tvalid-error:0.078341\ttrain-gini:0.976592\tvalid-gini:0.61005\n",
      "[80]\ttrain-error:0.045699\tvalid-error:0.078341\ttrain-gini:0.98422\tvalid-gini:0.614576\n",
      "[90]\ttrain-error:0.043395\tvalid-error:0.076805\ttrain-gini:0.987876\tvalid-gini:0.625757\n",
      "[100]\ttrain-error:0.041091\tvalid-error:0.076805\ttrain-gini:0.991516\tvalid-gini:0.631814\n",
      "[110]\ttrain-error:0.038786\tvalid-error:0.076805\ttrain-gini:0.993503\tvalid-gini:0.649784\n",
      "[120]\ttrain-error:0.035714\tvalid-error:0.076805\ttrain-gini:0.995901\tvalid-gini:0.655241\n",
      "[130]\ttrain-error:0.034178\tvalid-error:0.076805\ttrain-gini:0.997217\tvalid-gini:0.671414\n",
      "[140]\ttrain-error:0.029186\tvalid-error:0.076805\ttrain-gini:0.998174\tvalid-gini:0.68406\n",
      "[150]\ttrain-error:0.026882\tvalid-error:0.076805\ttrain-gini:0.998849\tvalid-gini:0.701298\n",
      "[160]\ttrain-error:0.024578\tvalid-error:0.076805\ttrain-gini:0.999242\tvalid-gini:0.703295\n",
      "[170]\ttrain-error:0.023041\tvalid-error:0.076805\ttrain-gini:0.999503\tvalid-gini:0.721131\n",
      "[180]\ttrain-error:0.019969\tvalid-error:0.081413\ttrain-gini:0.99971\tvalid-gini:0.725591\n",
      "[190]\ttrain-error:0.016513\tvalid-error:0.081413\ttrain-gini:0.999839\tvalid-gini:0.730116\n",
      "[200]\ttrain-error:0.013057\tvalid-error:0.079877\ttrain-gini:0.999892\tvalid-gini:0.733444\n",
      "[210]\ttrain-error:0.011905\tvalid-error:0.079877\ttrain-gini:0.999942\tvalid-gini:0.73777\n",
      "[220]\ttrain-error:0.010369\tvalid-error:0.079877\ttrain-gini:0.999963\tvalid-gini:0.743161\n",
      "[230]\ttrain-error:0.009217\tvalid-error:0.079877\ttrain-gini:0.999967\tvalid-gini:0.74995\n",
      "[240]\ttrain-error:0.008065\tvalid-error:0.078341\ttrain-gini:0.999975\tvalid-gini:0.752745\n",
      "[250]\ttrain-error:0.00768\tvalid-error:0.076805\ttrain-gini:0.999988\tvalid-gini:0.755208\n",
      "[260]\ttrain-error:0.006912\tvalid-error:0.078341\ttrain-gini:0.999992\tvalid-gini:0.756539\n",
      "[270]\ttrain-error:0.006528\tvalid-error:0.076805\ttrain-gini:0.999992\tvalid-gini:0.759468\n",
      "[280]\ttrain-error:0.004992\tvalid-error:0.076805\ttrain-gini:1\tvalid-gini:0.755208\n",
      "[290]\ttrain-error:0.00384\tvalid-error:0.076805\ttrain-gini:1\tvalid-gini:0.754676\n",
      "[300]\ttrain-error:0.00384\tvalid-error:0.076805\ttrain-gini:1\tvalid-gini:0.757937\n",
      "[310]\ttrain-error:0.002304\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.756872\n",
      "[320]\ttrain-error:0.002304\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.757072\n",
      "[330]\ttrain-error:0.002304\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.758469\n",
      "[340]\ttrain-error:0.001152\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.759667\n",
      "[350]\ttrain-error:0.001152\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.757937\n",
      "[360]\ttrain-error:0.000768\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.760466\n",
      "[370]\ttrain-error:0.000768\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.76173\n",
      "[380]\ttrain-error:0.000768\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.764592\n",
      "[390]\ttrain-error:0.000768\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.766855\n",
      "[400]\ttrain-error:0.000384\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.76619\n",
      "[410]\ttrain-error:0.000384\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.766389\n",
      "[420]\ttrain-error:0.000384\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.767654\n",
      "[430]\ttrain-error:0.000384\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.767454\n",
      "[440]\ttrain-error:0.000384\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.767654\n",
      "[450]\ttrain-error:0.000384\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.769251\n",
      "[460]\ttrain-error:0\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.768785\n",
      "[470]\ttrain-error:0\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.766922\n",
      "[480]\ttrain-error:0\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.766789\n",
      "[490]\ttrain-error:0\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.765923\n",
      "[500]\ttrain-error:0\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.765324\n",
      "[510]\ttrain-error:0\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.763661\n",
      "[520]\ttrain-error:0\tvalid-error:0.076805\ttrain-gini:1\tvalid-gini:0.764659\n",
      "[530]\ttrain-error:0\tvalid-error:0.076805\ttrain-gini:1\tvalid-gini:0.763328\n",
      "[540]\ttrain-error:0\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.762729\n",
      "[550]\ttrain-error:0\tvalid-error:0.076805\ttrain-gini:1\tvalid-gini:0.762729\n",
      "Stopping. Best iteration:\n",
      "[450]\ttrain-error:0.000384\tvalid-error:0.078341\ttrain-gini:1\tvalid-gini:0.769251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(b_train, 'train'), (b_valid, 'valid')]\n",
    "model_B = xgb.train(params, b_train, 3000, watchlist,feval=gini_xgb,early_stopping_rounds=100, maximize=True, verbose_eval=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.006377\tvalid-error:0.006182\ttrain-gini:0.974071\tvalid-gini:0.983197\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[10]\ttrain-error:0.005411\tvalid-error:0.006955\ttrain-gini:0.996495\tvalid-gini:0.993848\n",
      "[20]\ttrain-error:0.005024\tvalid-error:0.006955\ttrain-gini:0.998051\tvalid-gini:0.996915\n",
      "[30]\ttrain-error:0.004444\tvalid-error:0.006182\ttrain-gini:0.998575\tvalid-gini:0.99719\n",
      "[40]\ttrain-error:0.004251\tvalid-error:0.006182\ttrain-gini:0.998733\tvalid-gini:0.998092\n",
      "[50]\ttrain-error:0.003671\tvalid-error:0.006182\ttrain-gini:0.998977\tvalid-gini:0.998044\n",
      "[60]\ttrain-error:0.003478\tvalid-error:0.00541\ttrain-gini:0.999279\tvalid-gini:0.998187\n",
      "[70]\ttrain-error:0.003092\tvalid-error:0.004637\ttrain-gini:0.999413\tvalid-gini:0.998025\n",
      "[80]\ttrain-error:0.002319\tvalid-error:0.003864\ttrain-gini:0.999678\tvalid-gini:0.997788\n",
      "[90]\ttrain-error:0.002319\tvalid-error:0.003864\ttrain-gini:0.999889\tvalid-gini:0.99757\n",
      "[100]\ttrain-error:0.002126\tvalid-error:0.003864\ttrain-gini:0.999893\tvalid-gini:0.997427\n",
      "[110]\ttrain-error:0.001739\tvalid-error:0.003864\ttrain-gini:0.999914\tvalid-gini:0.997171\n",
      "[120]\ttrain-error:0.001739\tvalid-error:0.003864\ttrain-gini:0.999925\tvalid-gini:0.997228\n",
      "[130]\ttrain-error:0.001739\tvalid-error:0.003864\ttrain-gini:0.999944\tvalid-gini:0.997237\n",
      "[140]\ttrain-error:0.001739\tvalid-error:0.004637\ttrain-gini:0.999962\tvalid-gini:0.997427\n",
      "[150]\ttrain-error:0.001739\tvalid-error:0.004637\ttrain-gini:0.999976\tvalid-gini:0.997541\n",
      "Stopping. Best iteration:\n",
      "[58]\ttrain-error:0.003478\tvalid-error:0.00541\ttrain-gini:0.999261\tvalid-gini:0.998215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(c_train, 'train'), (c_valid, 'valid')]\n",
    "model_C = xgb.train(params, c_train, 3000, watchlist,feval=gini_xgb,\n",
    "                    early_stopping_rounds=100, maximize=True, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_preds = model_A.predict(a_test)\n",
    "b_preds = model_B.predict(b_test)\n",
    "c_preds = model_C.predict(c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_country_sub(preds, test_feat, country):\n",
    "    # make sure we code the country correctly\n",
    "    country_codes = ['A', 'B', 'C']\n",
    "    \n",
    "    # get just the poor probabilities\n",
    "    country_sub = pd.DataFrame(data=preds[:, ],  # proba p=1\n",
    "                               columns=['poor'], \n",
    "                               index=test_feat.index)\n",
    "\n",
    "    \n",
    "    # add the country code for joining later\n",
    "    country_sub[\"country\"] = country\n",
    "    return country_sub[[\"country\", \"poor\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_sub = make_country_sub(a_preds, A_test, 'A')\n",
    "b_sub = make_country_sub(b_preds, B_test, 'B')\n",
    "c_sub = make_country_sub(c_preds, C_test, 'C')\n",
    "submission = pd.concat([a_sub, b_sub, c_sub])\n",
    "submission.head()\n",
    "submission.to_csv('dsubmission.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
